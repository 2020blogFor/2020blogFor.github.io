---
title: 'Neural Operator, Graph Kernel Network for PDEs'
date: 2020-04-25
permalink: /posts/2020/04/BO/
tags:
  - BO
---
This is a blog post credit to Yujia Huang, Zongyi Li, and Jiawei Zhao

# Meta-learning: A Learning to Learn Approach
### Brief Introduction of Learning to Learn
The success of modern deep learning algorithms is remarkable. However, this kind of success is based on the huge datasets that are available to be used to train the model. For example, advanced deep learning  language models, like [gpt-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf), is pre-trained with around 40GB of text data. 

This kind of method of training a model from scratch can achieve excellent performance when there are abundant train data available. However, in many areas, the size of training data is limited, such as media image analysis. Also, when the new task we want to tackle is relevant to the previous task we have solved, it is not reasonable to train from scratch.   

On the other hand, humans can use their past experience to learn new things quickly. Babies have to learn everything from scratch, like how to walk, how to talk, etc. However, as the babies grow up, they will get the ability to use what they have learned before to learn new tasks. For example, people who know how to play Go can learn how to play chess very fast. This kind of ability is called "learning to learn", and we want to build a machine learning model that also has such ability.

### What is Meta learning

The idea of meta-learning is to learn the learning process. There are many types of meta-learning and this blog will focus on two methods which try to learn some hyperparameters (such as initialization parameters, learning rates) by learning from previous tasks. Other types meta-learning will be mentined in the last part. Basically, we will have two modules in meta-learning models. The first module is the same as a typical neural network and it can be regarded as a low-level network. Sometimes it called learner and optimizee. The second module is a higher level one called optimizer or meta-learner. It tries to teach learner to learn better.
